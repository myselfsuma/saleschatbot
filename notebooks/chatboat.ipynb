{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c0062bc7-e058-433e-8b36-5e54f7fee3fc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
    "from strategies import TotalSalesStrategy, TotalUnitsStrategy, MaxSalesStrategy\n",
    "from charts_utils import generate_sales_bar_chart, generate_units_bar_chart\n",
    "\n",
    "class SalesChatbot:\n",
    "    def __init__(self, csv_file):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.docs = [f\"Product: {row['Product']}, Total Sales: {row['Total Sales']}, Units Sold: {row['Units Sold']}\" \n",
    "                     for _, row in self.data.iterrows()]\n",
    "        self.embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "        self.vectorstore = FAISS.from_texts(self.docs, self.embedding_model)\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-small\")\n",
    "        model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-small\")\n",
    "        llm_pipeline = pipeline(\"text2text-generation\", model=model, tokenizer=tokenizer, device=-1)\n",
    "        self.llm = HuggingFacePipeline(pipeline=llm_pipeline)\n",
    "        self.strategies = {\n",
    "            \"total sales\": TotalSalesStrategy(),\n",
    "            \"total units\": TotalUnitsStrategy(),\n",
    "            \"highest sales\": MaxSalesStrategy()\n",
    "        }\n",
    "        self.chat_history = []\n",
    "\n",
    "    def answer_query(self, query):\n",
    "        for key in self.strategies:\n",
    "            if key in query.lower():\n",
    "                answer = self.strategies[key].handle(self.data, query)\n",
    "                self.chat_history.append({\"user\": query, \"bot\": answer})\n",
    "                return answer\n",
    "        if \"chart\" in query.lower() or \"graph\" in query.lower():\n",
    "            sales_chart = generate_sales_bar_chart(self.data)\n",
    "            units_chart = generate_units_bar_chart(self.data)\n",
    "            return f\"Generated charts:\\n- {sales_chart}\\n- {units_chart}\"\n",
    "        retrieved_docs = self.vectorstore.similarity_search(query, k=2)\n",
    "        context = \"\\n\".join([doc.page_content for doc in retrieved_docs])\n",
    "        history_text = \"\\n\".join([f\"User: {turn['user']}\\nBot: {turn['bot']}\" for turn in self.chat_history])\n",
    "        prompt = f\"\"\"\n",
    "Answer the user query based on the sales report context.\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Conversation History:\n",
    "{history_text}\n",
    "\n",
    "User: {query}\n",
    "Bot:\"\"\"\n",
    "        result = self.llm(prompt, max_length=200)[0]['generated_text'].strip()\n",
    "        self.chat_history.append({\"user\": query, \"bot\": result})\n",
    "        return result"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "chatboat",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
